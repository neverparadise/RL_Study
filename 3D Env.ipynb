{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from numpy.core._multiarray_umath import ndarray\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    # 가능한 action = left, right, up, down, high, low\n",
    "    action = np.array([[-1, 0, 0], [1, 0, 0], [0, 1, 0], [0, -1, 0], [0, 0, 1], [0, 0, -1]])\n",
    "    selection_action_pr = np.array([1 / 6, 1 / 6, 1 / 6, 1 / 6, 1 / 6, 1 / 6])\n",
    "\n",
    "    # 에이전트의 위치 초기화\n",
    "    def __init__(self):\n",
    "        self.pos = (0, 0, 0)\n",
    "\n",
    "    # 에이전트의 위치 저장\n",
    "    def set_pos(self, position):\n",
    "        self.pos = position\n",
    "        return self.pos\n",
    "\n",
    "    # 에이전트의 위치 불러오기\n",
    "    def get_pos(self):\n",
    "        return self.pos\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    # 1 좌표계 밖, 길, 목적지에 대한 보상 설정\n",
    "    cliff = -3\n",
    "    road = -1\n",
    "    goal = 1\n",
    "\n",
    "    # 2 목적지 좌표 설정\n",
    "    goal_position = [2, 2, 2]\n",
    "\n",
    "    # 3 보상리스트\n",
    "    reward_list = [\n",
    "        [[road, road, road], [road, road, road], [road, road, road]],\n",
    "        [[road, road, road], [road, road, road], [road, road, road]],\n",
    "        [[road, road, road], [road, road, road], [road, road, goal]]\n",
    "    ]\n",
    "\n",
    "    reward_list_str = [\n",
    "        [['road', 'road', 'road'],\n",
    "         ['road', 'road', 'road'],\n",
    "         ['road', 'road', 'road']],\n",
    "\n",
    "        [['road', 'road', 'road'],\n",
    "         ['road', 'road', 'road'],\n",
    "         ['road', 'road', 'road']],\n",
    "\n",
    "        [['road', 'road', 'road'],\n",
    "         ['road', 'road', 'road'],\n",
    "         ['road', 'road', 'goal']]\n",
    "    ]\n",
    "\n",
    "    # 4 보상리스트를 numpy array로 변환\n",
    "    def __init__(self):\n",
    "        self.reward = np.asarray(self.reward_list)\n",
    "\n",
    "    # 5  에이전트의 행동 결과 반환\n",
    "    def move(self, agent, action):\n",
    "        done = False  # done은 에피소드의 진행 여부를 알려주는 bool 변수\n",
    "\n",
    "        # 6.1 행동에 따른 좌표 구하기\n",
    "        # 현재좌표 : agent.pos\n",
    "        # 이동 후 좌표 : agent.pos + agent.action[action]\n",
    "\n",
    "        new_pos = agent.pos + agent.action[action]\n",
    "\n",
    "        # 6.2 현재 좌표가 목적지에 도달하였는가 확인\n",
    "        if self.reward_list_str[agent.pos[0]][agent.pos[1]][agent.pos[2]] == \"goal\":\n",
    "            reward = self.goal\n",
    "            observation = agent.set_pos(agent.pos)\n",
    "            done = True\n",
    "\n",
    "        elif new_pos[0] < 0 or self.reward.shape[0] <= new_pos[0] or new_pos[1] < 0 or self.reward.shape[1] <= new_pos[\n",
    "            1] or new_pos[2] < 0 or self.reward.shape[2] <= new_pos[2]:\n",
    "            reward = self.cliff\n",
    "            observation = agent.set_pos(agent.pos)\n",
    "            done = True\n",
    "\n",
    "        else:\n",
    "            observation = agent.set_pos(new_pos)\n",
    "            reward = self.reward[observation[0], observation[1]]\n",
    "\n",
    "        return observation, reward, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_value_function(env, agent, G, max_step, now_step):\n",
    "    print(\"State_Value_Function Part\")\n",
    "    print(type(G))\n",
    "    #1. 감가율 설정\n",
    "    gamma = 0.9\n",
    "\n",
    "    #2. 현재 위치가 도착위치인지 확인\n",
    "    if env.reward_list_str[agent.pos[0]][agent.pos[1]][agent.pos[2]] == \"goal\":\n",
    "        return env.goal\n",
    "\n",
    "    if (max_step == now_step):\n",
    "        pos1 = agent.get_pos()\n",
    "\n",
    "        for i in range(len(agent.action)):\n",
    "            agent.set_pos(pos1)\n",
    "            observation, reward, done = env.move(agent,i)\n",
    "            G += agent.selection_action_pr[i] * reward\n",
    "\n",
    "        G = int(G)\n",
    "        return G\n",
    "\n",
    "    #현재 상태의 보상을 계산한 후 다음 step으로 이동.\n",
    "    else:\n",
    "\n",
    "        pos1 = agent.get_pos()\n",
    "\n",
    "        for i in range(len(agent.action)):\n",
    "            observation, reward, done = env.move(agent, i)\n",
    "\n",
    "            G+= agent.selection_action_pr[i] * reward\n",
    "            if done == True:\n",
    "                if observation[0] < 0 or observation[0] >= env.reward.shape[0] or observation[1] < 0 or observation[1] >= env.reward.shape[1] or observation[2] < 0 or observation[2] >= env.reward.shape[2]:\n",
    "                    agent.set_pos(pos1)\n",
    "\n",
    "            next_v = state_value_function(env,agent,0,max_step,now_step+1)\n",
    "            G += agent.selection_action_pr[i] * next_v\n",
    "            agent.set_pos(pos1)\n",
    "        \n",
    "        G = int(G)\n",
    "        return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_3d_v_table(v_table, env):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # 시작지점 표시\n",
    "    start = np.array([0, 0, 0])\n",
    "    ax.scatter(start[0], start[1], start[2], s=50, color='red', depthshade=True, marker='s')\n",
    "\n",
    "    # 중간지점 표시\n",
    "    mid = np.array([1, 1, 1])\n",
    "    ax.scatter(mid[0], mid[1], mid[2], s=50, color='blue', depthshade=True, marker='^')\n",
    "\n",
    "    # 목적지 표시\n",
    "    goal = np.array([2, 2, 2])\n",
    "    ax.scatter(goal[0], goal[1], goal[2], s=50, color='green', depthshade=True, marker='o')\n",
    "\n",
    "    # 그리드 월드 그리기\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            line = np.array([[i, i, i], [0, 1, 2], [j, j, j]])\n",
    "            ax.plot(line[0], line[1], line[2], color='black')\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            line = np.array([[0, 1, 2], [i, i, i], [j, j, j]])\n",
    "            ax.plot(line[0], line[1], line[2], color='black')\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            line = np.array([[i, i, i], [j, j, j], [0, 1, 2]])\n",
    "            ax.plot(line[0], line[1], line[2], color='black')\n",
    "\n",
    "\n",
    "    # 소수점 생략\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%g'))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%g'))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%g'))\n",
    "\n",
    "    # X, Y, Z축의 라벨 설정\n",
    "    ax.set_xlabel('X', size=15)\n",
    "    ax.set_ylabel('Y', size=15)\n",
    "    ax.set_zlabel('Z', size=15)\n",
    "\n",
    "    # X, Y, Z 축의 눈금설정\n",
    "    ax.set_xticks([0, 1, 2])\n",
    "    ax.set_yticks([0, 1, 2])\n",
    "    ax.set_zticks([0, 1, 2])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # 가치함수값 표시\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                Axes3D.text((i), (j), (k), v_table[i,j,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n",
      "State_Value_Function Part\n",
      "<class 'int'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-efe2cc09d1dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_value_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mv_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-4cd1905eedae>\u001b[0m in \u001b[0;36mstate_value_function\u001b[1;34m(env, agent, G, max_step, now_step)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mG\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselection_action_pr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "max_step_number = 5\n",
    "\n",
    "time_len = []\n",
    "\n",
    "for max_step in range(max_step_number):\n",
    "\n",
    "    v_table = np.zeros((env.reward.shape[0], env.reward.shape[1], env.reward.shape[2]), dtype=float)\n",
    "    start_time = time.time()\n",
    "    for i in range(env.reward.shape[0]):\n",
    "        for j in range(env.reward.shape[1]):\n",
    "            for k in range(env.reward.shape[2]):\n",
    "                agent.set_pos([i,j,k])\n",
    "                print(agent.get_pos())\n",
    "                G = state_value_function(env, agent, 0, max_step, 0)\n",
    "                print(type(G))\n",
    "                v_table[i,j,k] = G \n",
    "\n",
    "\n",
    "    time_len.append(time.time()-start_time)\n",
    "    print(\"max_step_number = {} total_time = {}(s)\".format(max_step, np.round(time.time() - start_time,2)))\n",
    "\n",
    "    show_3d_v_table(v_table, env)\n",
    "\n",
    "plt.plot(time_len, 'o-k')\n",
    "plt.xlabel('max_down')\n",
    "plt.ylabel('time(s)')\n",
    "plt.legent()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
